{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbeb21b2-f068-454f-b64c-09ff505effc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select one out of 6 databases\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 1 for Amazon \n",
      "Enter 2 for BestBuy \n",
      "Enter 3 for kmart \n",
      "Enter 4 for Nike \n",
      "Enter 5 for Generic \n",
      "Enter 6 for Custom.\n",
      " 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each items :  \n",
      "\n",
      "                 Element  Count\n",
      "0                  Shams     11\n",
      "1             Bed Skirts     11\n",
      "2             Bedspreads      7\n",
      "3  Embroidered Bedspread      6\n",
      "4                 Sheets     10\n",
      "5    Bedding Collections      7\n",
      "6           Kids Bedding     12\n",
      "7     Decorative Pillows     10\n",
      "8                 Quilts      8\n",
      "This is a database of 20 transactions.Enter any value of support and confidence between 10 to 100%\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the support in percent:  70\n",
      "Enter the confidence in percent:  70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum support in quantity is  14\n",
      "Minimum confidence is  0.7\n",
      "Items with counts that satisfies the minimum support\n",
      "Empty DataFrame\n",
      "Columns: [Element, Count]\n",
      "Index: []\n",
      "Possible set of items meeting the minimum support\n",
      "Empty DataFrame\n",
      "Columns: [Items, Support]\n",
      "Index: []\n",
      "\n",
      "\n",
      "\n",
      "Frequent items are as below:\n",
      "\n",
      " Series([], Name: Items, dtype: float64)\n",
      "Empty DataFrame\n",
      "Columns: [Items, Confidence, ConfidenceOfreverse]\n",
      "Index: []\n",
      "No Association found between items with given support and confidence, Try with lesser support or confidence \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print('Please select one out of 6 databases')\n",
    "which_db=input('Enter 1 for Amazon \\nEnter 2 for BestBuy \\nEnter 3 for kmart \\nEnter 4 for Nike \\nEnter 5 for Generic \\nEnter 6 for Custom.\\n')\n",
    "\n",
    "if int(which_db)==1:\n",
    "    data=pd.read_excel('Amazon.xlsx')\n",
    "elif int(which_db)==2:\n",
    "    data=pd.read_excel('BestBuy.xlsx')\n",
    "elif int(which_db)==3:\n",
    "    data=pd.read_excel('kmart.xlsx')\n",
    "elif int(which_db)==4:\n",
    "    data=pd.read_excel('Nike.xlsx')\n",
    "elif int(which_db)==5:\n",
    "    data=pd.read_excel('Generic.xlsx')\n",
    "elif int(which_db)==6:\n",
    "    data=pd.read_excel('Custom.xlsx')\n",
    "else:\n",
    "    print('Accepted values are only 1 to 6, else the default database Amazon would be read')\n",
    "    data=pd.read_excel('Amazon.xlsx')\n",
    "    \n",
    "import ast\n",
    "rows=data['Transaction']\n",
    "uniques=[]\n",
    "temp=[]\n",
    "for eachrow in rows:\n",
    "    for eachelement in ast.literal_eval(eachrow):\n",
    "        temp.append(eachelement)\n",
    "uniques=set(temp)\n",
    "dicts={'Element': [each for each in uniques],\n",
    "      'Count':[temp.count(each) for each in uniques]}\n",
    "print('Count of each items :  \\n')\n",
    "\n",
    "iteration1=pd.DataFrame(dicts)\n",
    "print(iteration1)\n",
    "\n",
    "print('This is a database of 20 transactions.Enter any value of support and confidence between 10 to 100%')\n",
    "\n",
    "support_in_percent=int(input('Enter the support in percent: '))\n",
    "confidence_in_percent =int(input('Enter the confidence in percent: '))\n",
    "               \n",
    "Min_support=int(np.floor((support_in_percent/100)*len(data['Transaction'])))\n",
    "Min_confidence=confidence_in_percent/100\n",
    "\n",
    "print('Minimum support in quantity is ', Min_support)\n",
    "print('Minimum confidence is ', Min_confidence)\n",
    "\n",
    "OneItem_set = iteration1[iteration1.Count >= Min_support]\n",
    "print('Items with counts that satisfies the minimum support')\n",
    "print(OneItem_set)\n",
    "Combined=[]\n",
    "import itertools\n",
    "for i in range(1, len(OneItem_set)+1):\n",
    "    x=list(itertools.combinations(OneItem_set.Element, i))\n",
    "    Combined.append(x)\n",
    "    \n",
    "#print(Combined)\n",
    "# K-implies Iitemset containing set of 1, 2, 3...K elements iteratively\n",
    "import ast\n",
    "filtered=[]\n",
    "k=len(Combined)\n",
    "count=0\n",
    "elements=[]\n",
    "counts=[]\n",
    "#print(set(Combined[2][0]))\n",
    "for i in range(k):\n",
    "    for j in range(len(Combined[i])):\n",
    "        for each in rows:\n",
    "            each=ast.literal_eval(each)\n",
    "            #print(each)\n",
    "            if set(list(Combined[i][j])).issubset(each):\n",
    "                count=count + 1\n",
    "        counts.append(count)\n",
    "        elements.append(list(Combined[i][j]))\n",
    "        count=0\n",
    "                \n",
    "x={'Items': elements,\n",
    "    'Support': counts}\n",
    "datalist=pd.DataFrame(x)\n",
    "#print('Possible Set of items')\n",
    "#print(datalist)\n",
    "\n",
    "datalist=datalist[datalist.Support >= Min_support]\n",
    "print('Possible set of items meeting the minimum support')\n",
    "print(datalist)\n",
    "import itertools\n",
    "y=list(itertools.combinations(datalist.Items, 2))\n",
    "finalList=[]\n",
    "for i in range(len(y)):\n",
    "    x=list(y[i])\n",
    "    finalList.append(x)\n",
    "#print(finalList)\n",
    "FL=[]\n",
    "for i in range(len(finalList)):\n",
    "    a=finalList[i][0]\n",
    "    b=finalList[i][1]\n",
    "    if not any(x in a for x in b):\n",
    "        FL.append(finalList[i])  \n",
    "print('\\n\\n')\n",
    "freq1item=[]\n",
    "if len(FL)==0:\n",
    "    print('Frequent items are as below:\\n\\n',datalist['Items'])\n",
    "else:\n",
    "    for i in range(len(FL)):\n",
    "        for j in range(len(FL[i])):\n",
    "            if ((FL[i][j] not in freq1item) and len(FL[i][j])==1):\n",
    "                freq1item.append(FL[i][j])\n",
    "\n",
    "\n",
    "    freq1item.append(FL)\n",
    "    print('Frequent items are as below:\\n\\n',freq1item)\n",
    "\n",
    "\n",
    "#Defining support and confidence\n",
    "mylist=[]\n",
    "flatlist=[]\n",
    "def supportboth(item):\n",
    "    counts=0\n",
    "    for j in range(len(data['Transaction'])):\n",
    "        flatlist=[ j for i in item for j in i]\n",
    "        flatlistset=set(flatlist)\n",
    "        #print(flatlistset)\n",
    "        everyrow=ast.literal_eval(data['Transaction'][j])\n",
    "        row=set(everyrow)\n",
    "        is_subset=flatlistset.issubset(row)\n",
    "        if is_subset:\n",
    "            counts=counts + 1\n",
    "    num=counts\n",
    "    denom= len(data['Transaction'])\n",
    "    return num/denom\n",
    "def supportfirst(item):\n",
    "    counts=0\n",
    "    for j in range(len(data['Transaction'])):\n",
    "        itemset=set(item)\n",
    "        everyrow=ast.literal_eval(data['Transaction'][j])\n",
    "        row=set(everyrow)\n",
    "        is_subset=itemset.issubset(row)\n",
    "        if is_subset:\n",
    "            counts=counts + 1\n",
    "    num=counts\n",
    "    denom= len(data['Transaction'])\n",
    "    return num/denom\n",
    "def confidence(items):\n",
    "    conf=supportboth(items)/supportfirst(items[0])\n",
    "    return conf\n",
    "def confidenceReverse(items):\n",
    "    conf=supportboth(items)/supportfirst(items[1])\n",
    "    return conf\n",
    "\n",
    "confidence_levels_rev=[]\n",
    "confidence_levels=[]\n",
    "for each in FL:\n",
    "    confidence_levels.append(confidence(each))\n",
    "    confidence_levels_rev.append(confidenceReverse(each))\n",
    "    \n",
    "\n",
    "dict_temp={'Items':FL,\n",
    "           'Confidence':confidence_levels,\n",
    "           'ConfidenceOfreverse':confidence_levels_rev\n",
    "          }\n",
    "x=pd.DataFrame(dict_temp)\n",
    "print(x)\n",
    "\n",
    "x1=x[x.Confidence >= Min_confidence]\n",
    "x2=x[x.ConfidenceOfreverse >= Min_confidence]\n",
    "\n",
    "if (len(x)==0):\n",
    "    print('No Association found between items with given support and confidence, Try with lesser support or confidence ')\n",
    "    \n",
    "elif(len(x1)==0 and len(x2)==0):\n",
    "        print('No Association can be found at the given confidence')\n",
    "        \n",
    "else:\n",
    "    print('Association rules found are:\\n')\n",
    "    ya=x1.Items.tolist()\n",
    "    yb=x2.Items.tolist()\n",
    "    conf=x1.Confidence.tolist()\n",
    "    confrev=x2.ConfidenceOfreverse.tolist()\n",
    "    for i in range(len(ya)):\n",
    "        print(ya[i][0],' --> ',ya[i][1],'    C =', format(conf[i],\".2f\"))\n",
    "    for i in range(len(yb)):\n",
    "        print(yb[i][1],' --> ',yb[i][0],'    C =', format(confrev[i],\".2f\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3068f-eba9-4693-a72d-652f390d9fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
